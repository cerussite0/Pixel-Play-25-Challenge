{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:42.987669Z",
     "iopub.status.busy": "2025-01-11T10:49:42.987352Z",
     "iopub.status.idle": "2025-01-11T10:49:50.563116Z",
     "shell.execute_reply": "2025-01-11T10:49:50.562328Z",
     "shell.execute_reply.started": "2025-01-11T10:49:42.987642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:50.564822Z",
     "iopub.status.busy": "2025-01-11T10:49:50.564194Z",
     "iopub.status.idle": "2025-01-11T10:49:50.568579Z",
     "shell.execute_reply": "2025-01-11T10:49:50.567711Z",
     "shell.execute_reply.started": "2025-01-11T10:49:50.564788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "from pathlib import Path\n",
    "train_dir = Path('/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:50.570453Z",
     "iopub.status.busy": "2025-01-11T10:49:50.570187Z",
     "iopub.status.idle": "2025-01-11T10:49:57.011282Z",
     "shell.execute_reply": "2025-01-11T10:49:57.010396Z",
     "shell.execute_reply.started": "2025-01-11T10:49:50.570421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defined the batch size here\n",
    "batch_size = 32\n",
    "# Image size 336 is used here because RandomCrop is used later to get a 224*224 part out\n",
    "img_height = 336\n",
    "img_width = 336\n",
    "\n",
    "# Carrying out the train test split\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  label_mode='categorical',\n",
    "  validation_split=0.2,\n",
    "  subset='training',\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  label_mode='categorical',\n",
    "  validation_split=0.2,\n",
    "  subset='validation',\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/input/embeddings_matrix2.csv')\n",
    "\n",
    "col_names=[]\n",
    "col_names.append(\"Classes\")\n",
    "for i in range (1,86):\n",
    "    col_names.append(f'dim{i}')\n",
    "df.columns=col_names\n",
    "\n",
    "df_columns = [f\"dim{i}\" for i in range(1, 86)]\n",
    "df['embedding'] = df[df_columns].values.tolist()\n",
    "for i in range(1,86):\n",
    "    df=df.drop(f'dim{i}',axis=1)\n",
    "    \n",
    "attribute_embs=df.set_index('Classes')['embedding'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=train_ds.class_names\n",
    "labelled_classes = {index: name for index, name in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_vectors(image, label):\n",
    "    # Converting labels to embedding vectors\n",
    "    class_name = labelled_classes[label.numpy()] \n",
    "    embedding_vector = attribute_embs[class_name]\n",
    "    \n",
    "    # Converting it to a tensor\n",
    "    embedding_vector = tf.convert_to_tensor(embedding_vector, dtype=tf.float32)\n",
    "    \n",
    "    return image, embedding_vector\n",
    "\n",
    "\n",
    "\n",
    "def embedding_vectors_with_shape(image, label):\n",
    "    image, embedding_vector = tf.py_function(\n",
    "        func=embedding_vectors,\n",
    "        inp=[image, label],\n",
    "        Tout=(tf.float32, tf.float32)\n",
    "    )\n",
    "\n",
    "    image.set_shape([img_height, img_width, 3])  \n",
    "    embedding_vector.set_shape([85])\n",
    "    return image, embedding_vector \n",
    "    \n",
    "train_ds = train_ds.map(embedding_vectors_with_shape)\n",
    "val_ds = val_ds.map(embedding_vectors_with_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:57.024317Z",
     "iopub.status.busy": "2025-01-11T10:49:57.024002Z",
     "iopub.status.idle": "2025-01-11T10:49:57.033934Z",
     "shell.execute_reply": "2025-01-11T10:49:57.033239Z",
     "shell.execute_reply.started": "2025-01-11T10:49:57.024287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initializing the model using sequential API\n",
    "model=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:57.035077Z",
     "iopub.status.busy": "2025-01-11T10:49:57.034851Z",
     "iopub.status.idle": "2025-01-11T10:49:57.070692Z",
     "shell.execute_reply": "2025-01-11T10:49:57.069708Z",
     "shell.execute_reply.started": "2025-01-11T10:49:57.035051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Implementing the data augmentation and pixel value rescaling layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.2),  \n",
    "    tf.keras.layers.RandomCrop(224, 224),\n",
    "    tf.keras.layers.Resizing(224, 224),\n",
    "    tf.keras.layers.Rescaling(1.0/255)      \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:57.071748Z",
     "iopub.status.busy": "2025-01-11T10:49:57.071476Z",
     "iopub.status.idle": "2025-01-11T10:49:58.149125Z",
     "shell.execute_reply": "2025-01-11T10:49:58.148472Z",
     "shell.execute_reply.started": "2025-01-11T10:49:57.071715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Using MobileNetV2 for feature extraction\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "# Freezing the pre-trained layers\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:58.151212Z",
     "iopub.status.busy": "2025-01-11T10:49:58.150967Z",
     "iopub.status.idle": "2025-01-11T10:49:58.156628Z",
     "shell.execute_reply": "2025-01-11T10:49:58.155834Z",
     "shell.execute_reply.started": "2025-01-11T10:49:58.151190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.add(data_augmentation)\n",
    "model.add(pretrained_model)\n",
    "# Adding layers for personalized task\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(40, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:49:58.157835Z",
     "iopub.status.busy": "2025-01-11T10:49:58.157578Z",
     "iopub.status.idle": "2025-01-11T10:49:58.180866Z",
     "shell.execute_reply": "2025-01-11T10:49:58.180066Z",
     "shell.execute_reply.started": "2025-01-11T10:49:58.157815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='Adam',  # Optimizer\n",
    "    loss=tf.keras.losses.MeanSquaredError,  # Loss function\n",
    "    metrics=['accuracy']  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:51:04.410041Z",
     "iopub.status.busy": "2025-01-11T10:51:04.409745Z",
     "iopub.status.idle": "2025-01-11T10:53:34.068333Z",
     "shell.execute_reply": "2025-01-11T10:53:34.067451Z",
     "shell.execute_reply.started": "2025-01-11T10:51:04.410019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T11:00:18.693681Z",
     "iopub.status.busy": "2025-01-11T11:00:18.693378Z",
     "iopub.status.idle": "2025-01-11T11:04:22.038309Z",
     "shell.execute_reply": "2025-01-11T11:04:22.037379Z",
     "shell.execute_reply.started": "2025-01-11T11:00:18.693659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Unfreezing the pretrained layers\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-11T10:49:37.401403Z",
     "iopub.status.idle": "2025-01-11T10:49:37.401777Z",
     "shell.execute_reply": "2025-01-11T10:49:37.401667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = ['antelope', 'bat', 'beaver', 'blue+whale', 'bobcat', 'buffalo', 'chihuahua', 'chimpanzee', 'collie', 'cow', 'dalmatian', 'deer', 'dolphin', 'elephant', 'fox', 'german+shepherd', 'giant+panda', 'giraffe', 'gorilla', 'grizzly+bear', 'hamster', 'hippopotamus', 'horse', 'humpback+whale', 'killer+whale', 'leopard', 'lion', 'mole', 'moose', 'mouse', 'otter', 'ox', 'persian+cat', 'pig', 'polar+bear', 'rabbit', 'raccoon', 'rat', 'rhinoceros', 'seal', 'sheep', 'siamese+cat', 'skunk', 'spider+monkey', 'squirrel', 'tiger', 'walrus', 'weasel', 'wolf', 'zebra']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-11T10:49:37.403108Z",
     "iopub.status.idle": "2025-01-11T10:49:37.403416Z",
     "shell.execute_reply": "2025-01-11T10:49:37.403293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Assuming pred_attribs is the predicted vector for a test image\n",
    "# and class_attributes is the attribute vector for each class (both seen and unseen)\n",
    "def predict_class(image_batch,model,attribute_embeddings):\n",
    "    \n",
    "    similarities = {}\n",
    "    pred_attribs=model.predict(image_batch)\n",
    "    batch_pred=[]\n",
    "    for attrib in pred_attribs:\n",
    "        for class_name, class_attributes in attribute_embeddings.items():\n",
    "            similarity = cosine(attrib, class_attributes)\n",
    "            similarities[class_name] = similarity\n",
    "            \n",
    "        # Sort by similarity\n",
    "        sorted_classes = sorted(similarities, key=similarities.get)\n",
    "        batch_pred.append(sorted_classes[0]) # Most similar class\n",
    "    \n",
    "    return  (batch_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:48:24.669778Z",
     "iopub.status.busy": "2025-01-11T10:48:24.669271Z",
     "iopub.status.idle": "2025-01-11T10:48:24.676775Z",
     "shell.execute_reply": "2025-01-11T10:48:24.675061Z",
     "shell.execute_reply.started": "2025-01-11T10:48:24.669745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Path to the test dataset\n",
    "test_dir = '/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test'\n",
    "\n",
    "# List of image file paths (assuming all images are in the same directory)\n",
    "image_paths = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir) if fname.endswith('.jpg')]\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (336, 336))  \n",
    "    return image\n",
    "\n",
    "# Load and preprocess\n",
    "images = [load_image(path) for path in image_paths]\n",
    "\n",
    "batch_size = 32\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "image_dataset = image_dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# For all images in batch\n",
    "for image_batch in image_dataset:\n",
    "    predictions.extend(predict_class(image_batch,model,attribute_embs))\n",
    "\n",
    "\n",
    "# Preparing csv\n",
    "results = {\n",
    "    'image': [os.path.basename(path) for path in image_paths],\n",
    "    'label': predictions\n",
    "}\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.columns=['image_id','class']\n",
    "df=df.sort_values('image_id')\n",
    "df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'submission.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10740331,
     "sourceId": 90860,
     "sourceType": "competition"
    },
    {
     "datasetId": 6455218,
     "sourceId": 10415378,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6455289,
     "sourceId": 10415468,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6459126,
     "sourceId": 10421320,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6460302,
     "sourceId": 10422929,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6460332,
     "sourceId": 10422984,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6460383,
     "sourceId": 10423062,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6460544,
     "sourceId": 10423314,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6460556,
     "sourceId": 10423331,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 213864,
     "modelInstanceId": 191904,
     "sourceId": 224976,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 213890,
     "modelInstanceId": 191933,
     "sourceId": 225007,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
